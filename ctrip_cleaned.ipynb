{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "932f5454-0443-46e1-be1d-7b7cf255e712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9c3c9cc-918a-48f0-b402-3421fd679ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      username  rating                                            content  \\\n",
      "0       æ¡œæ¡œæ¡œæ¡œæ¡œæ¡œ     4.7  å¸¦å¦ˆå¦ˆä¹Ÿç®—äº²å­æ¸¸å§ğŸ˜‚ å®¢è§‚çš„è¯´ï¼Œæˆ‘å¾ˆå–œæ¬¢è¿™é‡Œï¼Œæœ‰100å¤šç§å…°èŠ±ï¼Œä¸æ˜¯å“ªé‡Œéƒ½å¯ä»¥çœ‹åˆ°è¿™ä¹ˆå¤šå“ç§...   \n",
      "1         åŒ¿åç”¨æˆ·     4.0  èƒ¡å§¬èŠ±å›­ä½œä¸ºä¸–ç•Œé—äº§å€¼å¾—æ‰“å¡ï¼Œå°¤å…¶æ˜¯æœ‹å‹åœ¨å…¬å›­é‡Œè„šä¸Šç£¨å‡ºäº†ä¸€ä¸ªæ°´æ³¡ï¼Œå‰å°éå¸¸çƒ­æƒ…åœ°æ‹¿å‡ºäº†åˆ›å£...   \n",
      "2         åŒ¿åç”¨æˆ·     5.0  å‡ºç¥¨å¾ˆå¿«ï¼Œç»å¯¹å€¼å¾—ä¸€å»ï¼Œé‡Œé¢å¾ˆå¤§ï¼Œæ–°åŠ å¡å›½èŠ±ï¼Œå¾ˆå¤šå“ç§ï¼Œæ¤ç‰©çˆ±å¥½è€…çš„å¤©å ‚ï¼Œé—¨å£çš„çºªå¿µå“å’Œä¹¦ç±...   \n",
      "3  M27****9930     5.0  éå¸¸ç¾ä¸½çš„åœ°æ–¹ï¼Œå€¼å¾—ä¸€å»ã€‚æˆ‘ä¸ªäººæ„Ÿè§‰æ¯”æ»¨æµ·æ¹¾èŠ±å›­å¥½ã€‚ç‰¹åˆ«æ˜¯èƒ¡å§¬èŠ±é¦†ï¼Œå¾ˆå¤šå“ç§ç‹¬ç‰¹çš„è´è¶å…°ï¼Œç»™...   \n",
      "4         åŒ¿åç”¨æˆ·     5.0                 æ¯”ç°åœºä¹°ç¥¨ä¾¿å®œï¼Œé‡Œé¢å„ç§å…°ç§‘æ¤ç‰©éƒ½æœ‰ï¼Œè¿˜æœ‰ä¸€ä¸ªæ¸©å®¤ã€‚èƒ¡å§¬èŠ±éƒ½éå¸¸æ¼‚äº®   \n",
      "\n",
      "  ip_address        time      Attraction  \n",
      "0         ä¸Šæµ·  07/12/2023  Botanic Garden  \n",
      "1         æ±Ÿè‹  17/02/2024  Botanic Garden  \n",
      "2         å¹¿ä¸œ  07/10/2023  Botanic Garden  \n",
      "3         æ±Ÿè‹  12/08/2023  Botanic Garden  \n",
      "4       ä¸­å›½å°æ¹¾  07/12/2023  Botanic Garden  \n"
     ]
    }
   ],
   "source": [
    "# Define the path to your CSV file\n",
    "csv_file_path = 'Ctrip_reviews_details.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "# Specify the appropriate delimiter, encoding, and any other necessary parameters\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# For example, you can print the first few rows using df.head()\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21fda037-5362-4ee1-89e7-9a554d0ceafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently, attraction dataset has 21135 rows.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Currently, attraction dataset has {len(df)} rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f967f47c-de76-436d-b1cf-c3a7182f1d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently, attraction dataset has 21135 rows.\n"
     ]
    }
   ],
   "source": [
    "#remove rows with null value in the rating column\n",
    "df = pd.read_csv(csv_file_path, na_values=[''])\n",
    "df_cleaned = df.dropna(subset=['rating'])\n",
    "print(f\"Currently, attraction dataset has {len(df_cleaned)} rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80c3066e-8965-4e33-9c61-3bdfdbbed342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently, attraction dataset has 19981 rows.\n"
     ]
    }
   ],
   "source": [
    "# Define the condition for rows you want to remove\n",
    "condition = df_cleaned['rating'] < 1\n",
    "\n",
    "# Apply the condition to filter rows from the DataFrame\n",
    "df_filtered = df_cleaned[~condition]\n",
    "print(f\"Currently, attraction dataset has {len(df_filtered)} rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd128178-fc26-4ad2-979e-b2b68feede8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently, attraction dataset has 19417 rows.\n"
     ]
    }
   ],
   "source": [
    "#remove duplicate content\n",
    "new_df_filtered = df_filtered.drop_duplicates(subset=['content', 'username'], keep='first')\n",
    "print(f\"Currently, attraction dataset has {len(new_df_filtered)} rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b79a0d3-1a59-46e1-b352-22c392a62ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently, attraction dataset has 4125 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/3fg8120j4wjch312cnt4g2cc0000gn/T/ipykernel_91121/1932825221.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df_filtered['time'] = pd.to_datetime(new_df_filtered['time'], format='%d/%m/%Y')\n",
      "/var/folders/cj/3fg8120j4wjch312cnt4g2cc0000gn/T/ipykernel_91121/1932825221.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered1['time'] = df_filtered1['time'].dt.strftime('%d/%m/%Y')\n"
     ]
    }
   ],
   "source": [
    "# Convert 'time' column to datetime format with explicit date format and handle errors\n",
    "new_df_filtered['time'] = pd.to_datetime(new_df_filtered['time'], format='%d/%m/%Y')\n",
    "\n",
    "# Define the condition for rows you want to keep (date is after April 2022)\n",
    "condition = new_df_filtered['time'] >= pd.Timestamp('2022-04-01')\n",
    "\n",
    "# Apply the condition to filter rows from the DataFrame\n",
    "df_filtered1 = new_df_filtered[condition]\n",
    "\n",
    "print(f\"Currently, attraction dataset has {len(df_filtered1)} rows.\")\n",
    "\n",
    "df_filtered1['time'] = df_filtered1['time'].dt.strftime('%d/%m/%Y')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "baf0b29d-50e9-405f-b165-57eaaff083aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently, attraction dataset has 4050 rows.\n"
     ]
    }
   ],
   "source": [
    "#remove all non chinese words\n",
    "# Define a regular expression pattern to match Chinese characters\n",
    "chinese_pattern = re.compile(r'[\\p{Han}]')\n",
    "# Apply the regular expression pattern to filter out rows\n",
    "df_filtered3 = df_filtered1[df_filtered1['content'].apply(lambda x: bool(chinese_pattern.search(x)))]\n",
    "print(f\"Currently, attraction dataset has {len(df_filtered3)} rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eba48383-d049-4471-8377-197bc4e0ea52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      username  rating                                            content  \\\n",
      "0       æ¡œæ¡œæ¡œæ¡œæ¡œæ¡œ     4.7  å¸¦å¦ˆå¦ˆä¹Ÿç®—äº²å­æ¸¸å§ğŸ˜‚ å®¢è§‚çš„è¯´ï¼Œæˆ‘å¾ˆå–œæ¬¢è¿™é‡Œï¼Œæœ‰100å¤šç§å…°èŠ±ï¼Œä¸æ˜¯å“ªé‡Œéƒ½å¯ä»¥çœ‹åˆ°è¿™ä¹ˆå¤šå“ç§...   \n",
      "1         åŒ¿åç”¨æˆ·     4.0  èƒ¡å§¬èŠ±å›­ä½œä¸ºä¸–ç•Œé—äº§å€¼å¾—æ‰“å¡ï¼Œå°¤å…¶æ˜¯æœ‹å‹åœ¨å…¬å›­é‡Œè„šä¸Šç£¨å‡ºäº†ä¸€ä¸ªæ°´æ³¡ï¼Œå‰å°éå¸¸çƒ­æƒ…åœ°æ‹¿å‡ºäº†åˆ›å£...   \n",
      "2         åŒ¿åç”¨æˆ·     5.0  å‡ºç¥¨å¾ˆå¿«ï¼Œç»å¯¹å€¼å¾—ä¸€å»ï¼Œé‡Œé¢å¾ˆå¤§ï¼Œæ–°åŠ å¡å›½èŠ±ï¼Œå¾ˆå¤šå“ç§ï¼Œæ¤ç‰©çˆ±å¥½è€…çš„å¤©å ‚ï¼Œé—¨å£çš„çºªå¿µå“å’Œä¹¦ç±...   \n",
      "3  M27****9930     5.0  éå¸¸ç¾ä¸½çš„åœ°æ–¹ï¼Œå€¼å¾—ä¸€å»ã€‚æˆ‘ä¸ªäººæ„Ÿè§‰æ¯”æ»¨æµ·æ¹¾èŠ±å›­å¥½ã€‚ç‰¹åˆ«æ˜¯èƒ¡å§¬èŠ±é¦†ï¼Œå¾ˆå¤šå“ç§ç‹¬ç‰¹çš„è´è¶å…°ï¼Œç»™...   \n",
      "4         åŒ¿åç”¨æˆ·     5.0                 æ¯”ç°åœºä¹°ç¥¨ä¾¿å®œï¼Œé‡Œé¢å„ç§å…°ç§‘æ¤ç‰©éƒ½æœ‰ï¼Œè¿˜æœ‰ä¸€ä¸ªæ¸©å®¤ã€‚èƒ¡å§¬èŠ±éƒ½éå¸¸æ¼‚äº®   \n",
      "\n",
      "  ip_address        time      Attraction  \n",
      "0         ä¸Šæµ·  07/12/2023  Botanic Garden  \n",
      "1         æ±Ÿè‹  17/02/2024  Botanic Garden  \n",
      "2         å¹¿ä¸œ  07/10/2023  Botanic Garden  \n",
      "3         æ±Ÿè‹  12/08/2023  Botanic Garden  \n",
      "4       ä¸­å›½å°æ¹¾  07/12/2023  Botanic Garden  \n"
     ]
    }
   ],
   "source": [
    "# For example, you can print the first few rows using df.head()\n",
    "print(df_filtered3.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "985aae6f-7515-4457-8d1f-092506d72a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_filtered3.to_csv('new_data.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2d2ed6b-c0b9-4f0b-923f-954cd8bc8f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the 'content' column and save it to a new CSV file\n",
    "df_filtered3['content'].to_csv('ctrip_doc', index=False, header=['content'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
