{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec8f6d3a-2c54-4add-8b91-ddf668a03355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import en_nlp_utils\n",
    "import model_evaluation_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12788efb-1ee0-456f-b6a5-98b6c4b6b141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text processing started at 2024-06-23 22:39:27.459417\n"
     ]
    }
   ],
   "source": [
    "# Define default source path\n",
    "SRC_PATH = \"src/\"\n",
    "\n",
    "start_time = datetime.now()\n",
    "print(\"Text processing started at {}\".format(start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96ae3a2c-4707-4b96-86e3-241b00ae5360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df_review = pd.read_csv(SRC_PATH + \"en_hotel_review.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b5a1cf3-43d9-405b-bf30-387f5bab732b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mdf_review:\u001b[0m\n",
      "source                     0\n",
      "hotel_id                   0\n",
      "hotel_name                 0\n",
      "country                    0\n",
      "group_name                 0\n",
      "room_type                  0\n",
      "stay_length                0\n",
      "stay_date                  0\n",
      "review_score               0\n",
      "review_score_category      0\n",
      "sentiment                  0\n",
      "review_date                0\n",
      "review_title               1\n",
      "review                     0\n",
      "review_cleaned_v1        143\n",
      "dtype: int64\n",
      "\u001b[1mTotal rows in df_review:\u001b[0m 39974 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check NULL values\n",
    "en_nlp_utils.check_null(df_review, \"df_review\")\n",
    "\n",
    "# Remove rows when \"review_cleaned_v1\" is NULL\n",
    "df_review = df_review.dropna(subset=[\"review_cleaned_v1\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e42e1c-22d3-490a-b803-1aae86c8b614",
   "metadata": {},
   "source": [
    "# Using Full Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b4bfd7-c77e-4a3f-9e86-161ded937440",
   "metadata": {},
   "source": [
    "## 1) Data set partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "137026e3-96a9-4be8-b608-50c56108d63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features and labels\n",
    "X = df_review[\"review_cleaned_v1\"]\n",
    "y = df_review[\"sentiment\"]\n",
    "\n",
    "# Data set partitioning\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56f66622-eb89-4b83-a60d-05dae5c3cbd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target Label</th>\n",
       "      <th>Train Count</th>\n",
       "      <th>Test Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>25316</td>\n",
       "      <td>6360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>6548</td>\n",
       "      <td>1607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Target Label  Train Count  Test Count\n",
       "1     positive        25316        6360\n",
       "0     negative         6548        1607"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "trd = dict(Counter(y_train))\n",
    "tsd = dict(Counter(y_test))\n",
    "pd.DataFrame([[key, trd[key], tsd[key]] for key in trd], columns=[\"Target Label\", \"Train Count\", \"Test Count\"]).sort_values(by=[\"Train Count\", \"Test Count\"], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0029e4cd-54a4-4be6-aac9-2b92270b9376",
   "metadata": {},
   "source": [
    "## 2) Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0fea51-7b7a-467f-ac13-84016f1103bc",
   "metadata": {},
   "source": [
    "### a) Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee6b1680-1502-4647-9384-1e426be0d1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of Words\n",
    "bow_vectorizer = CountVectorizer()\n",
    "X_train_bow = bow_vectorizer.fit_transform(X_train)\n",
    "X_test_bow = bow_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d58317-b67e-44c7-af7a-3bfb44de8f4f",
   "metadata": {},
   "source": [
    "### b) TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6da01e5-afc5-442f-ad30-dbff872d6dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a79cdb3-b919-4842-b554-14e169e6eff5",
   "metadata": {},
   "source": [
    "## 3) Model training and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1d3719-260f-45f7-9b2b-e69788a6d18a",
   "metadata": {},
   "source": [
    "### a) Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26ddbeff-50ab-4250-88ad-3d4e59cd726e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes with BoW accuracy:  0.8223923685201456\n",
      "Naive Bayes with TF-IDF accuracy:  0.8260323835822769\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Trained using Bag of Words features\n",
    "nb_bow = MultinomialNB()\n",
    "nb_bow.fit(X_train_bow, y_train)\n",
    "y_pred_bow_nb = nb_bow.predict(X_test_bow)\n",
    "print(\"Naive Bayes with BoW accuracy: \", accuracy_score(y_test, y_pred_bow_nb))\n",
    "\n",
    "# Trained using TF-IDF features\n",
    "nb_tfidf = MultinomialNB()\n",
    "nb_tfidf.fit(X_train_tfidf, y_train)\n",
    "y_pred_tfidf_nb = nb_tfidf.predict(X_test_tfidf)\n",
    "print(\"Naive Bayes with TF-IDF accuracy: \", accuracy_score(y_test, y_pred_tfidf_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0857f4f9-e140-436e-bd65-0c1a1a49a558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes with BoW accuracy:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.56      0.54      0.55      1607\n",
      "    positive       0.88      0.89      0.89      6360\n",
      "\n",
      "    accuracy                           0.82      7967\n",
      "   macro avg       0.72      0.72      0.72      7967\n",
      "weighted avg       0.82      0.82      0.82      7967\n",
      "\n",
      "Naive Bayes with TF-IDF accuracy:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.20      0.32      1607\n",
      "    positive       0.83      0.98      0.90      6360\n",
      "\n",
      "    accuracy                           0.83      7967\n",
      "   macro avg       0.79      0.59      0.61      7967\n",
      "weighted avg       0.82      0.83      0.78      7967\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display classification report \n",
    "unique_classes = list(set(y_test))\n",
    "\n",
    "print(\"Naive Bayes with BoW accuracy:\")\n",
    "model_evaluation_utils.display_classification_report(true_labels=y_test, predicted_labels=y_pred_bow_nb, classes=unique_classes)\n",
    "\n",
    "print(\"Naive Bayes with TF-IDF accuracy:\")\n",
    "model_evaluation_utils.display_classification_report(true_labels=y_test, predicted_labels=y_pred_tfidf_nb, classes=unique_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04928122-b139-459d-8db7-fe60ab6390e0",
   "metadata": {},
   "source": [
    "### b) SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "499118a5-2972-4d56-84b2-190da89e3b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with BoW accuracy:  0.8315551650558554\n",
      "SVM with TF-IDF accuracy:  0.8393372662231706\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Trained using Bag of Words features\n",
    "svm_bow = LinearSVC(C=0.1, max_iter=5000)\n",
    "svm_bow.fit(X_train_bow, y_train)\n",
    "y_pred_bow_svm = svm_bow.predict(X_test_bow)\n",
    "print(\"SVM with BoW accuracy: \", accuracy_score(y_test, y_pred_bow_svm))\n",
    "\n",
    "# Trained using TF-IDF features\n",
    "svm_tfidf = LinearSVC()\n",
    "svm_tfidf.fit(X_train_tfidf, y_train)\n",
    "y_pred_tfidf_svm = svm_tfidf.predict(X_test_tfidf)\n",
    "print(\"SVM with TF-IDF accuracy: \", accuracy_score(y_test, y_pred_tfidf_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5363ebb1-a91e-4e02-a97e-aa7dd7b3b671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with BoW accuracy:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.42      0.50      1607\n",
      "    positive       0.87      0.93      0.90      6360\n",
      "\n",
      "    accuracy                           0.83      7967\n",
      "   macro avg       0.74      0.68      0.70      7967\n",
      "weighted avg       0.82      0.83      0.82      7967\n",
      "\n",
      "SVM with TF-IDF accuracy:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      0.48      0.55      1607\n",
      "    positive       0.88      0.93      0.90      6360\n",
      "\n",
      "    accuracy                           0.84      7967\n",
      "   macro avg       0.76      0.71      0.72      7967\n",
      "weighted avg       0.83      0.84      0.83      7967\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display classification report \n",
    "print(\"SVM with BoW accuracy:\")\n",
    "model_evaluation_utils.display_classification_report(true_labels=y_test, predicted_labels=y_pred_bow_svm, classes=unique_classes)\n",
    "\n",
    "print(\"SVM with TF-IDF accuracy:\")\n",
    "model_evaluation_utils.display_classification_report(true_labels=y_test, predicted_labels=y_pred_tfidf_svm, classes=unique_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4091115f-bdf2-43ac-ab66-5c9b91173fb2",
   "metadata": {},
   "source": [
    "### c) Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73cd5d53-8d2c-4930-aab2-4783262aa68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with BoW accuracy:  0.8349441445964604\n",
      "Logistic Regression with TF-IDF accuracy:  0.844860047696749\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Trained using Bag of Words features\n",
    "lr_bow = LogisticRegression(max_iter=1000)\n",
    "lr_bow.fit(X_train_bow, y_train)\n",
    "y_pred_bow_lr = lr_bow.predict(X_test_bow)\n",
    "print(\"Logistic Regression with BoW accuracy: \", accuracy_score(y_test, y_pred_bow_lr))\n",
    "\n",
    "# Trained using TF-IDF features\n",
    "lr_tfidf = LogisticRegression(max_iter=1000)\n",
    "lr_tfidf.fit(X_train_tfidf, y_train)\n",
    "y_pred_tfidf_lr = lr_tfidf.predict(X_test_tfidf)\n",
    "print(\"Logistic Regression with TF-IDF accuracy: \", accuracy_score(y_test, y_pred_tfidf_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "965f31d8-ed81-407e-9bd4-8618a9df584c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with BoW accuracy:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      0.45      0.52      1607\n",
      "    positive       0.87      0.93      0.90      6360\n",
      "\n",
      "    accuracy                           0.83      7967\n",
      "   macro avg       0.75      0.69      0.71      7967\n",
      "weighted avg       0.82      0.83      0.82      7967\n",
      "\n",
      "Logistic Regression with TF-IDF accuracy:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.45      0.54      1607\n",
      "    positive       0.87      0.94      0.91      6360\n",
      "\n",
      "    accuracy                           0.84      7967\n",
      "   macro avg       0.77      0.70      0.72      7967\n",
      "weighted avg       0.83      0.84      0.83      7967\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display classification report \n",
    "print(\"Logistic Regression with BoW accuracy:\")\n",
    "model_evaluation_utils.display_classification_report(true_labels=y_test, predicted_labels=y_pred_bow_lr, classes=unique_classes)\n",
    "\n",
    "print(\"Logistic Regression with TF-IDF accuracy:\")\n",
    "model_evaluation_utils.display_classification_report(true_labels=y_test, predicted_labels=y_pred_tfidf_lr, classes=unique_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367c14df-9b69-46ce-97da-09fe20512a70",
   "metadata": {},
   "source": [
    "### d) LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84a2bdc3-3713-4d59-89e3-ef7d2765f4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "498/498 - 41s - 82ms/step - accuracy: 0.8251 - loss: 0.3822 - val_accuracy: 0.8450 - val_loss: 0.3392\n",
      "Epoch 2/5\n",
      "498/498 - 43s - 87ms/step - accuracy: 0.8584 - loss: 0.3155 - val_accuracy: 0.8436 - val_loss: 0.3326\n",
      "Epoch 3/5\n",
      "498/498 - 45s - 90ms/step - accuracy: 0.8716 - loss: 0.2953 - val_accuracy: 0.8474 - val_loss: 0.3363\n",
      "Epoch 4/5\n",
      "498/498 - 45s - 89ms/step - accuracy: 0.8821 - loss: 0.2743 - val_accuracy: 0.8436 - val_loss: 0.3433\n",
      "Epoch 5/5\n",
      "498/498 - 44s - 89ms/step - accuracy: 0.8930 - loss: 0.2553 - val_accuracy: 0.8441 - val_loss: 0.3606\n",
      "249/249 - 4s - 16ms/step - accuracy: 0.8441 - loss: 0.3606\n",
      "LSTM accuracy:  0.844106912612915\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, SpatialDropout1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Converts the label to numeric form\n",
    "label_encoder = LabelEncoder()\n",
    "y2 = label_encoder.fit_transform(y) # Convert \"negative\" to 0, and \"positive\" to 1\n",
    "\n",
    "# Data set partitioning\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y2, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(X_train2)\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train2)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test2)\n",
    "\n",
    "# Padding sequences\n",
    "max_sequence_length = 100\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_sequence_length)\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_sequence_length)\n",
    "\n",
    "# LSTM model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=5000, output_dim=128))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(optimizer=Adam(learning_rate=1e-3), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train LSTM model\n",
    "model.fit(X_train_pad, y_train2, epochs=5, batch_size=64, validation_data=(X_test_pad, y_test2), verbose=2)\n",
    "\n",
    "# Evaluate model \n",
    "loss, accuracy = model.evaluate(X_test_pad, y_test2, verbose=2)\n",
    "print(\"LSTM accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1185fd8a-9b02-474f-bdd9-32cfa2d9945c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text processing ended at 2024-06-23 22:43:18.703596\n",
      "Text processing spent 0:03:51.244179\n"
     ]
    }
   ],
   "source": [
    "end_time = datetime.now()\n",
    "print(\"Text processing ended at {}\".format(end_time))\n",
    "print(\"Text processing spent {}\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e64081-171b-489d-8e07-5613b2480cfa",
   "metadata": {},
   "source": [
    "# Applying Stratified Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15873263-1535-4c8c-a335-12601f46d1e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stay_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>1691</td>\n",
       "      <td>5560</td>\n",
       "      <td>7251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>5364</td>\n",
       "      <td>21375</td>\n",
       "      <td>26739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>1100</td>\n",
       "      <td>4741</td>\n",
       "      <td>5841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>8155</td>\n",
       "      <td>31676</td>\n",
       "      <td>39831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           negative  positive  Total\n",
       "stay_date                           \n",
       "2022           1691      5560   7251\n",
       "2023           5364     21375  26739\n",
       "2024           1100      4741   5841\n",
       "Total          8155     31676  39831"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert \"stay_date\" and \"review_date\" columns as datetime data type\n",
    "df_review[\"stay_date\"] = pd.to_datetime(df_review[\"stay_date\"], format=\"%d/%m/%Y\")\n",
    "\n",
    "# Count number of reviews based on year and sentiment\n",
    "sentiment_count = df_review.groupby([df_review[\"sentiment\"], df_review[\"stay_date\"].dt.year]).size().reset_index(name=\"count\")\n",
    "sentiment_count2 = sentiment_count.pivot_table(index=\"stay_date\", columns=\"sentiment\", values=\"count\", \n",
    "                                               aggfunc=\"sum\", margins=True, margins_name=\"Total\")\n",
    "sentiment_count2.columns.name = None\n",
    "sentiment_count2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568566ed-467b-450a-b813-780aa7f61a1d",
   "metadata": {},
   "source": [
    "## 1) Stratified sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e8e5aea-f0f5-4a65-a5a7-2ed53e2939d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for stratified sampling\n",
    "def stratified_sample(df, stratify_col, frac):\n",
    "    return df.groupby(stratify_col, group_keys=False).apply(lambda x: x.sample(frac=frac))\n",
    "\n",
    "# Stratified sampling based on year and sentiment\n",
    "frac = 0.30  # Sampling ratio\n",
    "sampled_2022 = stratified_sample(df_review[df_review[\"stay_date\"].dt.year == 2022], \"sentiment\", frac)\n",
    "sampled_2023 = stratified_sample(df_review[df_review[\"stay_date\"].dt.year == 2023], \"sentiment\", frac)\n",
    "sampled_2024 = stratified_sample(df_review[df_review[\"stay_date\"].dt.year == 2024], \"sentiment\", frac)\n",
    "\n",
    "# Merge the sampled data\n",
    "sampled_data = pd.concat([sampled_2022, sampled_2023, sampled_2024])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41379741-df53-4a74-80ac-afa97fc7ebbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stay_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>507</td>\n",
       "      <td>1668</td>\n",
       "      <td>2175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>1609</td>\n",
       "      <td>6412</td>\n",
       "      <td>8021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>330</td>\n",
       "      <td>1422</td>\n",
       "      <td>1752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>2446</td>\n",
       "      <td>9502</td>\n",
       "      <td>11948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           negative  positive  Total\n",
       "stay_date                           \n",
       "2022            507      1668   2175\n",
       "2023           1609      6412   8021\n",
       "2024            330      1422   1752\n",
       "Total          2446      9502  11948"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count number of reviews based on year and sentiment\n",
    "sampled_sentiment_count = sampled_data.groupby([sampled_data[\"sentiment\"], sampled_data[\"stay_date\"].dt.year]).size().reset_index(name=\"count\")\n",
    "sampled_sentiment_count2 = sampled_sentiment_count.pivot_table(index=\"stay_date\", columns=\"sentiment\", values=\"count\", \n",
    "                                               aggfunc=\"sum\", margins=True, margins_name=\"Total\")\n",
    "sampled_sentiment_count2.columns.name = None\n",
    "sampled_sentiment_count2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b997bc-c3a9-404b-ace6-9d7ec2caa5bd",
   "metadata": {},
   "source": [
    "## 2) Data set partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4a42061-d491-4dde-a736-8501c407c79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features and labels\n",
    "X = sampled_data[\"review_cleaned_v1\"]\n",
    "y = sampled_data[\"sentiment\"]\n",
    "\n",
    "# Data set partitioning\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5dbe370b-272a-4b58-ba75-85296ab817bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target Label</th>\n",
       "      <th>Train Count</th>\n",
       "      <th>Test Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>7616</td>\n",
       "      <td>1886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>1942</td>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Target Label  Train Count  Test Count\n",
       "0     positive         7616        1886\n",
       "1     negative         1942         504"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trd = dict(Counter(y_train))\n",
    "tsd = dict(Counter(y_test))\n",
    "pd.DataFrame([[key, trd[key], tsd[key]] for key in trd], columns=[\"Target Label\", \"Train Count\", \"Test Count\"]).sort_values(by=[\"Train Count\", \"Test Count\"], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72103420-24f1-492b-a182-9c64f7de4fb4",
   "metadata": {},
   "source": [
    "## 3) Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4f7b62-f2a5-44e8-ab4a-16a0340c3833",
   "metadata": {},
   "source": [
    "### a) Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3de155c-b3eb-4811-a064-a1dbf5011b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of Words\n",
    "bow_vectorizer = CountVectorizer()\n",
    "X_train_bow = bow_vectorizer.fit_transform(X_train)\n",
    "X_test_bow = bow_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62ae731-a87c-4d65-a2a0-18f416843b15",
   "metadata": {},
   "source": [
    "### b) TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f772a348-90d2-4702-bb27-7b64f6055c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99799e0-8b2b-4671-9f7b-e0f173dc0192",
   "metadata": {},
   "source": [
    "## 4) Model training and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb52d0af-fb2d-4f06-b65a-3ef8b0d52b77",
   "metadata": {},
   "source": [
    "### a) Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f9fde911-7c21-4109-af90-7e6352e4ef66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes with BoW accuracy:  0.8317991631799163\n",
      "Naive Bayes with TF-IDF accuracy:  0.8108786610878661\n"
     ]
    }
   ],
   "source": [
    "# Trained using Bag of Words features\n",
    "nb_bow = MultinomialNB()\n",
    "nb_bow.fit(X_train_bow, y_train)\n",
    "y_pred_bow_nb = nb_bow.predict(X_test_bow)\n",
    "print(\"Naive Bayes with BoW accuracy: \", accuracy_score(y_test, y_pred_bow_nb))\n",
    "\n",
    "# Trained using TF-IDF features\n",
    "nb_tfidf = MultinomialNB()\n",
    "nb_tfidf.fit(X_train_tfidf, y_train)\n",
    "y_pred_tfidf_nb = nb_tfidf.predict(X_test_tfidf)\n",
    "print(\"Naive Bayes with TF-IDF accuracy: \", accuracy_score(y_test, y_pred_tfidf_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8f8e4c4-fee4-4b6b-9b15-3fa976630f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes with BoW accuracy:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      0.48      0.55       504\n",
      "    positive       0.87      0.93      0.90      1886\n",
      "\n",
      "    accuracy                           0.83      2390\n",
      "   macro avg       0.75      0.70      0.72      2390\n",
      "weighted avg       0.82      0.83      0.82      2390\n",
      "\n",
      "Naive Bayes with TF-IDF accuracy:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.12      0.21       504\n",
      "    positive       0.81      1.00      0.89      1886\n",
      "\n",
      "    accuracy                           0.81      2390\n",
      "   macro avg       0.84      0.56      0.55      2390\n",
      "weighted avg       0.82      0.81      0.75      2390\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display classification report \n",
    "unique_classes = list(set(y_test))\n",
    "\n",
    "print(\"Naive Bayes with BoW accuracy:\")\n",
    "model_evaluation_utils.display_classification_report(true_labels=y_test, predicted_labels=y_pred_bow_nb, classes=unique_classes)\n",
    "\n",
    "print(\"Naive Bayes with TF-IDF accuracy:\")\n",
    "model_evaluation_utils.display_classification_report(true_labels=y_test, predicted_labels=y_pred_tfidf_nb, classes=unique_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fdfb8b-a5b5-4558-99aa-0b31a2586293",
   "metadata": {},
   "source": [
    "### b) SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c0ac2354-a8f8-43de-939a-f419a5d0fdcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with BoW accuracy:  0.8271966527196652\n",
      "SVM with TF-IDF accuracy:  0.8309623430962343\n"
     ]
    }
   ],
   "source": [
    "# Trained using Bag of Words features\n",
    "svm_bow = LinearSVC(C=0.1, max_iter=5000)\n",
    "svm_bow.fit(X_train_bow, y_train)\n",
    "y_pred_bow_svm = svm_bow.predict(X_test_bow)\n",
    "print(\"SVM with BoW accuracy: \", accuracy_score(y_test, y_pred_bow_svm))\n",
    "\n",
    "# Trained using TF-IDF features\n",
    "svm_tfidf = LinearSVC()\n",
    "svm_tfidf.fit(X_train_tfidf, y_train)\n",
    "y_pred_tfidf_svm = svm_tfidf.predict(X_test_tfidf)\n",
    "print(\"SVM with TF-IDF accuracy: \", accuracy_score(y_test, y_pred_tfidf_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe26b2e3-8ada-4db1-a1c7-a6031064c2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with BoW accuracy:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.42      0.51       504\n",
      "    positive       0.86      0.94      0.90      1886\n",
      "\n",
      "    accuracy                           0.83      2390\n",
      "   macro avg       0.75      0.68      0.70      2390\n",
      "weighted avg       0.81      0.83      0.81      2390\n",
      "\n",
      "SVM with TF-IDF accuracy:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.46      0.53       504\n",
      "    positive       0.87      0.93      0.90      1886\n",
      "\n",
      "    accuracy                           0.83      2390\n",
      "   macro avg       0.75      0.69      0.71      2390\n",
      "weighted avg       0.82      0.83      0.82      2390\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display classification report \n",
    "print(\"SVM with BoW accuracy:\")\n",
    "model_evaluation_utils.display_classification_report(true_labels=y_test, predicted_labels=y_pred_bow_svm, classes=unique_classes)\n",
    "\n",
    "print(\"SVM with TF-IDF accuracy:\")\n",
    "model_evaluation_utils.display_classification_report(true_labels=y_test, predicted_labels=y_pred_tfidf_svm, classes=unique_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0132be19-81ae-428b-8ec2-72f9ef0da26d",
   "metadata": {},
   "source": [
    "### c) Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "582c82c1-b941-4d1f-ab92-44c5e965902d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with BoW accuracy:  0.8288702928870293\n",
      "Logistic Regression with TF-IDF accuracy:  0.8301255230125523\n"
     ]
    }
   ],
   "source": [
    "# Trained using Bag of Words features\n",
    "lr_bow = LogisticRegression(max_iter=1000)\n",
    "lr_bow.fit(X_train_bow, y_train)\n",
    "y_pred_bow_lr = lr_bow.predict(X_test_bow)\n",
    "print(\"Logistic Regression with BoW accuracy: \", accuracy_score(y_test, y_pred_bow_lr))\n",
    "\n",
    "# Trained using TF-IDF features\n",
    "lr_tfidf = LogisticRegression(max_iter=1000)\n",
    "lr_tfidf.fit(X_train_tfidf, y_train)\n",
    "y_pred_tfidf_lr = lr_tfidf.predict(X_test_tfidf)\n",
    "print(\"Logistic Regression with TF-IDF accuracy: \", accuracy_score(y_test, y_pred_tfidf_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bc7e56d8-e096-496a-a9da-94ccbe252744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with BoW accuracy:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.43      0.52       504\n",
      "    positive       0.86      0.93      0.90      1886\n",
      "\n",
      "    accuracy                           0.83      2390\n",
      "   macro avg       0.75      0.68      0.71      2390\n",
      "weighted avg       0.81      0.83      0.82      2390\n",
      "\n",
      "Logistic Regression with TF-IDF accuracy:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.34      0.46       504\n",
      "    positive       0.84      0.96      0.90      1886\n",
      "\n",
      "    accuracy                           0.83      2390\n",
      "   macro avg       0.77      0.65      0.68      2390\n",
      "weighted avg       0.81      0.83      0.81      2390\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display classification report \n",
    "print(\"Logistic Regression with BoW accuracy:\")\n",
    "model_evaluation_utils.display_classification_report(true_labels=y_test, predicted_labels=y_pred_bow_lr, classes=unique_classes)\n",
    "\n",
    "print(\"Logistic Regression with TF-IDF accuracy:\")\n",
    "model_evaluation_utils.display_classification_report(true_labels=y_test, predicted_labels=y_pred_tfidf_lr, classes=unique_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62457a13-d9da-4030-a993-cea05fa29b75",
   "metadata": {},
   "source": [
    "### d) LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b0999a18-7ec4-401b-bdbe-276bc2f8ae07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "150/150 - 16s - 108ms/step - accuracy: 0.8002 - loss: 0.4516 - val_accuracy: 0.8209 - val_loss: 0.3791\n",
      "Epoch 2/5\n",
      "150/150 - 14s - 91ms/step - accuracy: 0.8487 - loss: 0.3435 - val_accuracy: 0.8343 - val_loss: 0.3528\n",
      "Epoch 3/5\n",
      "150/150 - 15s - 97ms/step - accuracy: 0.8732 - loss: 0.3003 - val_accuracy: 0.8402 - val_loss: 0.3629\n",
      "Epoch 4/5\n",
      "150/150 - 14s - 92ms/step - accuracy: 0.8876 - loss: 0.2695 - val_accuracy: 0.8331 - val_loss: 0.3905\n",
      "Epoch 5/5\n",
      "150/150 - 14s - 92ms/step - accuracy: 0.9009 - loss: 0.2469 - val_accuracy: 0.8301 - val_loss: 0.4139\n",
      "75/75 - 1s - 16ms/step - accuracy: 0.8301 - loss: 0.4139\n",
      "LSTM accuracy:  0.8301255106925964\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, SpatialDropout1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Converts the label to numeric form\n",
    "label_encoder = LabelEncoder()\n",
    "y2 = label_encoder.fit_transform(y) # Convert \"negative\" to 0, and \"positive\" to 1\n",
    "\n",
    "# Data set partitioning\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y2, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(X_train2)\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train2)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test2)\n",
    "\n",
    "# Padding sequences\n",
    "max_sequence_length = 100\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_sequence_length)\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_sequence_length)\n",
    "\n",
    "# LSTM model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=5000, output_dim=128))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(optimizer=Adam(learning_rate=1e-3), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train LSTM model\n",
    "model.fit(X_train_pad, y_train2, epochs=5, batch_size=64, validation_data=(X_test_pad, y_test2), verbose=2)\n",
    "\n",
    "# Evaluate model \n",
    "loss, accuracy = model.evaluate(X_test_pad, y_test2, verbose=2)\n",
    "print(\"LSTM accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "94b11f31-5110-40a7-980a-134429c61937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text processing ended at 2024-06-23 22:44:41.650135\n",
      "Text processing spent 0:05:14.190718\n"
     ]
    }
   ],
   "source": [
    "end_time = datetime.now()\n",
    "print(\"Text processing ended at {}\".format(end_time))\n",
    "print(\"Text processing spent {}\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89c2214-e042-470e-9ecb-24c0b6460bd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
